{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "single_folder = \"data/SINGLEframes\"\n",
    "double_folder = \"data/DOUBLEframes\"\n",
    "\n",
    "current_folder = single_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1\n",
    "\n",
    "\"\"\"\n",
    "Firstly, I converted the input color images to the grayscale images, and then used the Canny edge detection \n",
    "algorithm to find the edges of the images. Secondly I converted the input images from BGR color space to HSV color\n",
    "space. The detect_court_color function defines a threshold range for detecting the color of the court and creates \n",
    "a mask based on the color range. And then it calculates the number of white pixels in the mask and the total number\n",
    "of pixels in the image. It will judge whether the court exists based on the ratio of white pixels and a predefined \n",
    "threshold. The detect_quadrilateral_in_contours function finds contours in the image. For each contour, \n",
    "it calculates the perimeter and approximates the contour to a polygon. If the approximated polygon has four vertices,\n",
    "it will return True. If these two functions both return True, it indicates that a badminton court is detected.\n",
    "The results would be output to the folders named \"source\" and \"yolov5-master/data/images\".\n",
    "\"\"\"\n",
    "def detect_badminton_court(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray_img, 50, 150, apertureSize=3)\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    court_color = detect_court_color(imgHSV)\n",
    "    court_edge, quadrilateral = detect_quadrilateral_in_contours(edges)\n",
    "\n",
    "    court_present = court_color and court_edge\n",
    "#     return court_present, edges, quadrilateral\n",
    "    return court_present\n",
    "\n",
    "\n",
    "def detect_quadrilateral_in_contours(edge_image):\n",
    "    contours, _ = cv2.findContours(edge_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approximation = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "        if len(approximation) == 4:\n",
    "            return True, approximation\n",
    "    return False, None\n",
    "\n",
    "def detect_court_color(imgHSV, threshold=0.1):\n",
    "    lower = np.array([64, 84, 74])\n",
    "    upper = np.array([100, 145, 255])\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    white_pixels = np.sum(mask == 255)\n",
    "    total_pixels = mask.shape[0] * mask.shape[1]\n",
    "    court_ratio = white_pixels / total_pixels\n",
    "    court_exists = court_ratio > threshold\n",
    "    return court_exists\n",
    "\n",
    "images_directory = current_folder\n",
    "output_directory = \"source\"\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "for filename in os.listdir(images_directory):\n",
    "    image_path = os.path.join(images_directory, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    if detect_badminton_court(image):\n",
    "        cv2.imwrite(os.path.join(output_directory, filename), image)\n",
    "        cv2.imwrite(os.path.join('yolov5-master/data/images', filename), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2\n",
    "'''\n",
    "First, I loaded the images and converted them to grayscale. And then I used thresholding and edge detection to obtain contours in the image.\n",
    "I detected lines in the image using the Hough transform and stores the detected lines in the all_lines list. Finally, I drew the detected \n",
    "lines on the original image and saved the results to the folder named \"processed_source\".\n",
    "'''\n",
    "\n",
    "directory = 'source'\n",
    "\n",
    "all_files = os.listdir(directory)\n",
    "\n",
    "image_paths = [os.path.join(directory, f) for f in all_files if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
    "all_lines = []\n",
    "\n",
    "p1 = (183, 337)\n",
    "p2 = (1099, 337)\n",
    "p3 = (183, 719)\n",
    "p4 = (1099, 719)\n",
    "\n",
    "\n",
    "\n",
    "for path in image_paths:\n",
    "    img_org = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img_org, cv2.COLOR_BGR2GRAY)\n",
    "    ret, th1 = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)\n",
    "    roi = th1[p1[1]:p4[1], p1[0]:p4[0]]\n",
    "    v = np.median(roi)\n",
    "    sigma = 0.33\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edges_roi = cv2.Canny(roi, 50, 150, apertureSize=3)\n",
    "\n",
    "    linesP = cv2.HoughLinesP(edges_roi, rho=1, theta=np.pi/180, threshold=120, minLineLength=10, maxLineGap=14)\n",
    "    if linesP is not None:\n",
    "        for line in linesP:\n",
    "            all_lines.append(line)\n",
    "    \n",
    "    for line in all_lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img_org, (x1+p1[0], y1+p1[1]), (x2+p1[0], y2+p1[1]), (0, 255, 0), 3)\n",
    "    cv2.imwrite('processed_source/' + path.removeprefix('source/'), img_org)\n",
    "\n",
    "# img_org = cv.imread('1.jpeg')\n",
    "for line in all_lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img_org, (x1+p1[0], y1+p1[1]), (x2+p1[0], y2+p1[1]), (0, 255, 0), 3)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(img_org, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Detected Lines'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "modified_lines = []\n",
    "\n",
    "if all_lines is not None:\n",
    "    modified_lines = np.zeros_like(all_lines)  # Create an array with the same shape as linesP\n",
    "    for i in range(len(all_lines)):\n",
    "        l = all_lines[i][0]\n",
    "        #  Adjustment of coordinates\n",
    "        modified_line = [l[0] + p1[0], l[1] + p1[1], l[2] + p1[0], l[3] + p1[1]]\n",
    "        modified_lines[i][0] = modified_line\n",
    "\n",
    "black_background = np.zeros_like(img_org)\n",
    "\n",
    "for line in modified_lines:\n",
    "    l = line[0]  # Get a list of actual line coordinates\n",
    "    x1, y1, x2, y2 = l # And then unpack these four coordinates\n",
    "    cv2.line(black_background, (x1, y1), (x2, y2), (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(black_background, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Detected Lines (in red)'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5-master/yolov5s.pt, source=yolov5-master/data/images, data=yolov5-master/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.65, iou_thres=0.55, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5-master/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 ðŸš€ 2024-2-8 Python-3.9.6 torch-2.2.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "image 1/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame100-SINGLE.jpeg: 384x640 2 persons, 54.9ms\n",
      "image 2/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame101-SINGLE.jpeg: 384x640 2 persons, 62.4ms\n",
      "image 3/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame102-SINGLE.jpeg: 384x640 2 persons, 59.8ms\n",
      "image 4/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame103-SINGLE.jpeg: 384x640 2 persons, 52.3ms\n",
      "image 5/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame104-SINGLE.jpeg: 384x640 2 persons, 56.0ms\n",
      "image 6/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame105-SINGLE.jpeg: 384x640 2 persons, 62.7ms\n",
      "image 7/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame106-SINGLE.jpeg: 384x640 2 persons, 56.6ms\n",
      "image 8/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame107-SINGLE.jpeg: 384x640 2 persons, 67.6ms\n",
      "image 9/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame108-SINGLE.jpeg: 384x640 2 persons, 66.5ms\n",
      "image 10/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame109-SINGLE.jpeg: 384x640 2 persons, 61.5ms\n",
      "image 11/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame110-SINGLE.jpeg: 384x640 2 persons, 52.9ms\n",
      "image 12/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame111-SINGLE.jpeg: 384x640 2 persons, 53.5ms\n",
      "image 13/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame112-SINGLE.jpeg: 384x640 2 persons, 47.2ms\n",
      "image 14/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame113-SINGLE.jpeg: 384x640 2 persons, 54.4ms\n",
      "image 15/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame114-SINGLE.jpeg: 384x640 2 persons, 56.4ms\n",
      "image 16/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame115-SINGLE.jpeg: 384x640 2 persons, 60.5ms\n",
      "image 17/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame116-SINGLE.jpeg: 384x640 2 persons, 65.0ms\n",
      "image 18/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame117-SINGLE.jpeg: 384x640 2 persons, 76.8ms\n",
      "image 19/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame118-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 20/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame119-SINGLE.jpeg: 384x640 2 persons, 59.7ms\n",
      "image 21/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame120-SINGLE.jpeg: 384x640 2 persons, 59.6ms\n",
      "image 22/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame121-SINGLE.jpeg: 384x640 2 persons, 61.9ms\n",
      "image 23/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame122-SINGLE.jpeg: 384x640 2 persons, 59.9ms\n",
      "image 24/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame123-SINGLE.jpeg: 384x640 2 persons, 58.5ms\n",
      "image 25/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame124-SINGLE.jpeg: 384x640 2 persons, 55.6ms\n",
      "image 26/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame125-SINGLE.jpeg: 384x640 2 persons, 65.2ms\n",
      "image 27/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame126-SINGLE.jpeg: 384x640 2 persons, 58.0ms\n",
      "image 28/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame127-SINGLE.jpeg: 384x640 2 persons, 54.7ms\n",
      "image 29/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame128-SINGLE.jpeg: 384x640 2 persons, 51.2ms\n",
      "image 30/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame129-SINGLE.jpeg: 384x640 2 persons, 54.4ms\n",
      "image 31/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame130-SINGLE.jpeg: 384x640 2 persons, 56.1ms\n",
      "image 32/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame131-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 33/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame132-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 34/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame133-SINGLE.jpeg: 384x640 2 persons, 55.9ms\n",
      "image 35/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame135-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 36/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame136-SINGLE.jpeg: 384x640 2 persons, 62.3ms\n",
      "image 37/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame137-SINGLE.jpeg: 384x640 2 persons, 60.1ms\n",
      "image 38/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame138-SINGLE.jpeg: 384x640 2 persons, 60.2ms\n",
      "image 39/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame139-SINGLE.jpeg: 384x640 2 persons, 60.3ms\n",
      "image 40/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame140-SINGLE.jpeg: 384x640 2 persons, 64.2ms\n",
      "image 41/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame141-SINGLE.jpeg: 384x640 2 persons, 58.3ms\n",
      "image 42/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame142-SINGLE.jpeg: 384x640 2 persons, 62.8ms\n",
      "image 43/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame143-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 44/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame144-SINGLE.jpeg: 384x640 2 persons, 67.7ms\n",
      "image 45/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame145-SINGLE.jpeg: 384x640 2 persons, 53.3ms\n",
      "image 46/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame146-SINGLE.jpeg: 384x640 2 persons, 55.2ms\n",
      "image 47/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame147-SINGLE.jpeg: 384x640 2 persons, 50.4ms\n",
      "image 48/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame148-SINGLE.jpeg: 384x640 2 persons, 87.9ms\n",
      "image 49/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame149-SINGLE.jpeg: 384x640 2 persons, 56.0ms\n",
      "image 50/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame150-SINGLE.jpeg: 384x640 2 persons, 52.1ms\n",
      "image 51/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame151-SINGLE.jpeg: 384x640 2 persons, 66.7ms\n",
      "image 52/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame152-SINGLE.jpeg: 384x640 2 persons, 60.7ms\n",
      "image 53/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame153-SINGLE.jpeg: 384x640 2 persons, 58.5ms\n",
      "image 54/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame155-SINGLE.jpeg: 384x640 2 persons, 60.1ms\n",
      "image 55/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame156-SINGLE.jpeg: 384x640 2 persons, 68.1ms\n",
      "image 56/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame157-SINGLE.jpeg: 384x640 2 persons, 59.1ms\n",
      "image 57/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame158-SINGLE.jpeg: 384x640 2 persons, 77.0ms\n",
      "image 58/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame159-SINGLE.jpeg: 384x640 2 persons, 62.1ms\n",
      "image 59/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame160-SINGLE.jpeg: 384x640 2 persons, 83.8ms\n",
      "image 60/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame161-SINGLE.jpeg: 384x640 2 persons, 52.3ms\n",
      "image 61/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame162-SINGLE.jpeg: 384x640 2 persons, 50.4ms\n",
      "image 62/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame163-SINGLE.jpeg: 384x640 2 persons, 58.1ms\n",
      "image 63/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame164-SINGLE.jpeg: 384x640 2 persons, 55.1ms\n",
      "image 64/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame165-SINGLE.jpeg: 384x640 2 persons, 63.7ms\n",
      "image 65/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame166-SINGLE.jpeg: 384x640 2 persons, 54.9ms\n",
      "image 66/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame167-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 67/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame168-SINGLE.jpeg: 384x640 2 persons, 64.4ms\n",
      "image 68/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame169-SINGLE.jpeg: 384x640 2 persons, 64.9ms\n",
      "image 69/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame170-SINGLE.jpeg: 384x640 2 persons, 58.8ms\n",
      "image 70/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame171-SINGLE.jpeg: 384x640 2 persons, 62.1ms\n",
      "image 71/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame172-SINGLE.jpeg: 384x640 2 persons, 74.3ms\n",
      "image 72/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame173-SINGLE.jpeg: 384x640 2 persons, 57.8ms\n",
      "image 73/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame174-SINGLE.jpeg: 384x640 2 persons, 56.6ms\n",
      "image 74/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame175-SINGLE.jpeg: 384x640 2 persons, 56.4ms\n",
      "image 75/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame176-SINGLE.jpeg: 384x640 2 persons, 57.5ms\n",
      "image 76/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame177-SINGLE.jpeg: 384x640 2 persons, 57.9ms\n",
      "image 77/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame178-SINGLE.jpeg: 384x640 2 persons, 66.6ms\n",
      "image 78/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame179-SINGLE.jpeg: 384x640 2 persons, 69.2ms\n",
      "image 79/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame180-SINGLE.jpeg: 384x640 2 persons, 61.6ms\n",
      "image 80/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame181-SINGLE.jpeg: 384x640 2 persons, 63.3ms\n",
      "image 81/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame182-SINGLE.jpeg: 384x640 2 persons, 58.4ms\n",
      "image 82/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame183-SINGLE.jpeg: 384x640 2 persons, 59.4ms\n",
      "image 83/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame184-SINGLE.jpeg: 384x640 2 persons, 63.4ms\n",
      "image 84/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame185-SINGLE.jpeg: 384x640 2 persons, 62.3ms\n",
      "image 85/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame186-SINGLE.jpeg: 384x640 3 persons, 61.3ms\n",
      "image 86/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame187-SINGLE.jpeg: 384x640 3 persons, 74.4ms\n",
      "image 87/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame188-SINGLE.jpeg: 384x640 3 persons, 66.5ms\n",
      "image 88/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame189-SINGLE.jpeg: 384x640 3 persons, 62.6ms\n",
      "image 89/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame19-SINGLE.jpeg: 384x640 2 persons, 69.0ms\n",
      "image 90/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame190-SINGLE.jpeg: 384x640 3 persons, 62.3ms\n",
      "image 91/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame191-SINGLE.jpeg: 384x640 3 persons, 63.2ms\n",
      "image 92/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame192-SINGLE.jpeg: 384x640 3 persons, 60.7ms\n",
      "image 93/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame193-SINGLE.jpeg: 384x640 3 persons, 62.4ms\n",
      "image 94/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame194-SINGLE.jpeg: 384x640 3 persons, 65.3ms\n",
      "image 95/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame195-SINGLE.jpeg: 384x640 3 persons, 54.2ms\n",
      "image 96/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame196-SINGLE.jpeg: 384x640 3 persons, 54.9ms\n",
      "image 97/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame197-SINGLE.jpeg: 384x640 3 persons, 73.3ms\n",
      "image 98/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame198-SINGLE.jpeg: 384x640 3 persons, 69.3ms\n",
      "image 99/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame199-SINGLE.jpeg: 384x640 3 persons, 55.6ms\n",
      "image 100/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame20-SINGLE.jpeg: 384x640 2 persons, 50.6ms\n",
      "image 101/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame200-SINGLE.jpeg: 384x640 3 persons, 57.1ms\n",
      "image 102/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame201-SINGLE.jpeg: 384x640 3 persons, 59.6ms\n",
      "image 103/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame202-SINGLE.jpeg: 384x640 3 persons, 55.1ms\n",
      "image 104/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame203-SINGLE.jpeg: 384x640 3 persons, 55.0ms\n",
      "image 105/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame204-SINGLE.jpeg: 384x640 2 persons, 52.1ms\n",
      "image 106/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame205-SINGLE.jpeg: 384x640 2 persons, 53.4ms\n",
      "image 107/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame206-SINGLE.jpeg: 384x640 2 persons, 56.3ms\n",
      "image 108/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame207-SINGLE.jpeg: 384x640 2 persons, 67.7ms\n",
      "image 109/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame208-SINGLE.jpeg: 384x640 2 persons, 58.5ms\n",
      "image 110/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame209-SINGLE.jpeg: 384x640 2 persons, 56.4ms\n",
      "image 111/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame21-SINGLE.jpeg: 384x640 2 persons, 59.6ms\n",
      "image 112/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame210-SINGLE.jpeg: 384x640 2 persons, 64.7ms\n",
      "image 113/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame211-SINGLE.jpeg: 384x640 2 persons, 57.6ms\n",
      "image 114/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame212-SINGLE.jpeg: 384x640 2 persons, 55.0ms\n",
      "image 115/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame213-SINGLE.jpeg: 384x640 3 persons, 49.5ms\n",
      "image 116/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame214-SINGLE.jpeg: 384x640 3 persons, 54.9ms\n",
      "image 117/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame215-SINGLE.jpeg: 384x640 3 persons, 57.1ms\n",
      "image 118/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame216-SINGLE.jpeg: 384x640 3 persons, 54.1ms\n",
      "image 119/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame217-SINGLE.jpeg: 384x640 3 persons, 54.5ms\n",
      "image 120/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame218-SINGLE.jpeg: 384x640 3 persons, 64.2ms\n",
      "image 121/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame219-SINGLE.jpeg: 384x640 3 persons, 57.6ms\n",
      "image 122/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame22-SINGLE.jpeg: 384x640 2 persons, 54.8ms\n",
      "image 123/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame220-SINGLE.jpeg: 384x640 3 persons, 69.8ms\n",
      "image 124/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame221-SINGLE.jpeg: 384x640 3 persons, 61.7ms\n",
      "image 125/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame222-SINGLE.jpeg: 384x640 3 persons, 59.3ms\n",
      "image 126/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame223-SINGLE.jpeg: 384x640 3 persons, 58.0ms\n",
      "image 127/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame224-SINGLE.jpeg: 384x640 3 persons, 61.4ms\n",
      "image 128/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame225-SINGLE.jpeg: 384x640 2 persons, 65.7ms\n",
      "image 129/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame226-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 130/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame227-SINGLE.jpeg: 384x640 2 persons, 54.2ms\n",
      "image 131/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame228-SINGLE.jpeg: 384x640 2 persons, 56.4ms\n",
      "image 132/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame229-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 133/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame23-SINGLE.jpeg: 384x640 2 persons, 54.0ms\n",
      "image 134/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame230-SINGLE.jpeg: 384x640 2 persons, 56.0ms\n",
      "image 135/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame231-SINGLE.jpeg: 384x640 2 persons, 58.5ms\n",
      "image 136/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame232-SINGLE.jpeg: 384x640 2 persons, 54.4ms\n",
      "image 137/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame233-SINGLE.jpeg: 384x640 2 persons, 73.5ms\n",
      "image 138/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame234-SINGLE.jpeg: 384x640 2 persons, 58.1ms\n",
      "image 139/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame235-SINGLE.jpeg: 384x640 2 persons, 59.2ms\n",
      "image 140/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame236-SINGLE.jpeg: 384x640 2 persons, 59.8ms\n",
      "image 141/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame237-SINGLE.jpeg: 384x640 1 person, 60.1ms\n",
      "image 142/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame238-SINGLE.jpeg: 384x640 1 person, 59.8ms\n",
      "image 143/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame239-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 144/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame24-SINGLE.jpeg: 384x640 2 persons, 56.9ms\n",
      "image 145/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame240-SINGLE.jpeg: 384x640 3 persons, 53.2ms\n",
      "image 146/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame241-SINGLE.jpeg: 384x640 2 persons, 57.0ms\n",
      "image 147/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame242-SINGLE.jpeg: 384x640 2 persons, 55.2ms\n",
      "image 148/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame244-SINGLE.jpeg: 384x640 2 persons, 58.8ms\n",
      "image 149/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame245-SINGLE.jpeg: 384x640 2 persons, 57.2ms\n",
      "image 150/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame246-SINGLE.jpeg: 384x640 2 persons, 59.1ms\n",
      "image 151/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame247-SINGLE.jpeg: 384x640 2 persons, 55.5ms\n",
      "image 152/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame248-SINGLE.jpeg: 384x640 2 persons, 58.2ms\n",
      "image 153/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame249-SINGLE.jpeg: 384x640 2 persons, 76.1ms\n",
      "image 154/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame25-SINGLE.jpeg: 384x640 2 persons, 58.4ms\n",
      "image 155/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame250-SINGLE.jpeg: 384x640 2 persons, 87.7ms\n",
      "image 156/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame251-SINGLE.jpeg: 384x640 2 persons, 52.4ms\n",
      "image 157/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame252-SINGLE.jpeg: 384x640 2 persons, 53.2ms\n",
      "image 158/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame253-SINGLE.jpeg: 384x640 2 persons, 54.4ms\n",
      "image 159/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame254-SINGLE.jpeg: 384x640 2 persons, 51.2ms\n",
      "image 160/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame255-SINGLE.jpeg: 384x640 2 persons, 58.6ms\n",
      "image 161/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame257-SINGLE.jpeg: 384x640 2 persons, 52.3ms\n",
      "image 162/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame258-SINGLE.jpeg: 384x640 2 persons, 56.1ms\n",
      "image 163/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame259-SINGLE.jpeg: 384x640 2 persons, 58.7ms\n",
      "image 164/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame26-SINGLE.jpeg: 384x640 2 persons, 57.8ms\n",
      "image 165/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame260-SINGLE.jpeg: 384x640 2 persons, 52.1ms\n",
      "image 166/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame261-SINGLE.jpeg: 384x640 2 persons, 52.7ms\n",
      "image 167/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame262-SINGLE.jpeg: 384x640 2 persons, 56.6ms\n",
      "image 168/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame263-SINGLE.jpeg: 384x640 2 persons, 56.6ms\n",
      "image 169/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame264-SINGLE.jpeg: 384x640 2 persons, 59.4ms\n",
      "image 170/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame265-SINGLE.jpeg: 384x640 2 persons, 52.5ms\n",
      "image 171/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame267-SINGLE.jpeg: 384x640 2 persons, 57.4ms\n",
      "image 172/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame268-SINGLE.jpeg: 384x640 2 persons, 59.3ms\n",
      "image 173/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame269-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 174/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame27-SINGLE.jpeg: 384x640 2 persons, 52.2ms\n",
      "image 175/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame270-SINGLE.jpeg: 384x640 2 persons, 49.2ms\n",
      "image 176/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame271-SINGLE.jpeg: 384x640 2 persons, 54.0ms\n",
      "image 177/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame272-SINGLE.jpeg: 384x640 2 persons, 57.1ms\n",
      "image 178/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame273-SINGLE.jpeg: 384x640 2 persons, 54.0ms\n",
      "image 179/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame274-SINGLE.jpeg: 384x640 2 persons, 48.4ms\n",
      "image 180/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame275-SINGLE.jpeg: 384x640 2 persons, 58.7ms\n",
      "image 181/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame276-SINGLE.jpeg: 384x640 2 persons, 56.6ms\n",
      "image 182/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame277-SINGLE.jpeg: 384x640 2 persons, 50.1ms\n",
      "image 183/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame278-SINGLE.jpeg: 384x640 2 persons, 55.9ms\n",
      "image 184/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame279-SINGLE.jpeg: 384x640 2 persons, 52.0ms\n",
      "image 185/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame28-SINGLE.jpeg: 384x640 2 persons, 51.4ms\n",
      "image 186/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame280-SINGLE.jpeg: 384x640 2 persons, 49.8ms\n",
      "image 187/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame281-SINGLE.jpeg: 384x640 2 persons, 54.5ms\n",
      "image 188/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame282-SINGLE.jpeg: 384x640 2 persons, 61.8ms\n",
      "image 189/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame283-SINGLE.jpeg: 384x640 2 persons, 57.4ms\n",
      "image 190/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame284-SINGLE.jpeg: 384x640 2 persons, 54.9ms\n",
      "image 191/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame285-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 192/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame286-SINGLE.jpeg: 384x640 2 persons, 59.6ms\n",
      "image 193/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame287-SINGLE.jpeg: 384x640 2 persons, 50.0ms\n",
      "image 194/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame288-SINGLE.jpeg: 384x640 2 persons, 51.2ms\n",
      "image 195/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame289-SINGLE.jpeg: 384x640 2 persons, 56.5ms\n",
      "image 196/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame29-SINGLE.jpeg: 384x640 2 persons, 57.7ms\n",
      "image 197/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame290-SINGLE.jpeg: 384x640 2 persons, 59.4ms\n",
      "image 198/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame291-SINGLE.jpeg: 384x640 2 persons, 65.0ms\n",
      "image 199/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame292-SINGLE.jpeg: 384x640 2 persons, 58.6ms\n",
      "image 200/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame293-SINGLE.jpeg: 384x640 2 persons, 52.3ms\n",
      "image 201/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame294-SINGLE.jpeg: 384x640 2 persons, 52.6ms\n",
      "image 202/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame295-SINGLE.jpeg: 384x640 2 persons, 54.1ms\n",
      "image 203/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame296-SINGLE.jpeg: 384x640 2 persons, 49.0ms\n",
      "image 204/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame297-SINGLE.jpeg: 384x640 2 persons, 52.8ms\n",
      "image 205/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame298-SINGLE.jpeg: 384x640 2 persons, 56.9ms\n",
      "image 206/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame299-SINGLE.jpeg: 384x640 2 persons, 54.0ms\n",
      "image 207/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame30-SINGLE.jpeg: 384x640 2 persons, 57.6ms\n",
      "image 208/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame300-SINGLE.jpeg: 384x640 2 persons, 53.6ms\n",
      "image 209/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame301-SINGLE.jpeg: 384x640 2 persons, 59.1ms\n",
      "image 210/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame302-SINGLE.jpeg: 384x640 2 persons, 72.0ms\n",
      "image 211/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame303-SINGLE.jpeg: 384x640 2 persons, 55.9ms\n",
      "image 212/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame304-SINGLE.jpeg: 384x640 2 persons, 55.9ms\n",
      "image 213/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame305-SINGLE.jpeg: 384x640 2 persons, 58.1ms\n",
      "image 214/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame306-SINGLE.jpeg: 384x640 2 persons, 64.2ms\n",
      "image 215/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame307-SINGLE.jpeg: 384x640 2 persons, 55.9ms\n",
      "image 216/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame308-SINGLE.jpeg: 384x640 2 persons, 64.2ms\n",
      "image 217/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame309-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 218/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame31-SINGLE.jpeg: 384x640 2 persons, 58.5ms\n",
      "image 219/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame310-SINGLE.jpeg: 384x640 2 persons, 54.5ms\n",
      "image 220/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame311-SINGLE.jpeg: 384x640 2 persons, 46.9ms\n",
      "image 221/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame312-SINGLE.jpeg: 384x640 2 persons, 52.7ms\n",
      "image 222/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame313-SINGLE.jpeg: 384x640 2 persons, 54.5ms\n",
      "image 223/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame314-SINGLE.jpeg: 384x640 2 persons, 60.8ms\n",
      "image 224/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame315-SINGLE.jpeg: 384x640 2 persons, 49.9ms\n",
      "image 225/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame316-SINGLE.jpeg: 384x640 2 persons, 51.0ms\n",
      "image 226/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame317-SINGLE.jpeg: 384x640 2 persons, 59.7ms\n",
      "image 227/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame318-SINGLE.jpeg: 384x640 2 persons, 57.6ms\n",
      "image 228/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame319-SINGLE.jpeg: 384x640 2 persons, 51.0ms\n",
      "image 229/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame32-SINGLE.jpeg: 384x640 2 persons, 54.6ms\n",
      "image 230/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame320-SINGLE.jpeg: 384x640 2 persons, 63.0ms\n",
      "image 231/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame321-SINGLE.jpeg: 384x640 2 persons, 60.5ms\n",
      "image 232/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame322-SINGLE.jpeg: 384x640 2 persons, 53.3ms\n",
      "image 233/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame323-SINGLE.jpeg: 384x640 2 persons, 52.5ms\n",
      "image 234/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame324-SINGLE.jpeg: 384x640 2 persons, 56.1ms\n",
      "image 235/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame325-SINGLE.jpeg: 384x640 2 persons, 56.2ms\n",
      "image 236/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame326-SINGLE.jpeg: 384x640 2 persons, 51.1ms\n",
      "image 237/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame327-SINGLE.jpeg: 384x640 2 persons, 55.5ms\n",
      "image 238/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame328-SINGLE.jpeg: 384x640 2 persons, 49.6ms\n",
      "image 239/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame329-SINGLE.jpeg: 384x640 2 persons, 50.2ms\n",
      "image 240/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame33-SINGLE.jpeg: 384x640 2 persons, 52.3ms\n",
      "image 241/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame330-SINGLE.jpeg: 384x640 2 persons, 52.4ms\n",
      "image 242/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame331-SINGLE.jpeg: 384x640 2 persons, 55.4ms\n",
      "image 243/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame332-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 244/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame333-SINGLE.jpeg: 384x640 2 persons, 54.1ms\n",
      "image 245/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame334-SINGLE.jpeg: 384x640 2 persons, 51.0ms\n",
      "image 246/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame335-SINGLE.jpeg: 384x640 2 persons, 51.2ms\n",
      "image 247/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame336-SINGLE.jpeg: 384x640 2 persons, 55.4ms\n",
      "image 248/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame337-SINGLE.jpeg: 384x640 2 persons, 56.1ms\n",
      "image 249/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame338-SINGLE.jpeg: 384x640 2 persons, 58.9ms\n",
      "image 250/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame339-SINGLE.jpeg: 384x640 2 persons, 51.3ms\n",
      "image 251/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame34-SINGLE.jpeg: 384x640 2 persons, 90.2ms\n",
      "image 252/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame340-SINGLE.jpeg: 384x640 2 persons, 63.2ms\n",
      "image 253/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame341-SINGLE.jpeg: 384x640 2 persons, 72.5ms\n",
      "image 254/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame342-SINGLE.jpeg: 384x640 2 persons, 74.5ms\n",
      "image 255/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame343-SINGLE.jpeg: 384x640 2 persons, 76.0ms\n",
      "image 256/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame344-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 257/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame345-SINGLE.jpeg: 384x640 2 persons, 57.9ms\n",
      "image 258/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame346-SINGLE.jpeg: 384x640 2 persons, 57.1ms\n",
      "image 259/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame347-SINGLE.jpeg: 384x640 2 persons, 52.8ms\n",
      "image 260/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame348-SINGLE.jpeg: 384x640 1 person, 50.8ms\n",
      "image 261/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame349-SINGLE.jpeg: 384x640 2 persons, 49.6ms\n",
      "image 262/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame35-SINGLE.jpeg: 384x640 2 persons, 54.6ms\n",
      "image 263/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame350-SINGLE.jpeg: 384x640 1 person, 61.3ms\n",
      "image 264/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame351-SINGLE.jpeg: 384x640 1 person, 53.1ms\n",
      "image 265/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame352-SINGLE.jpeg: 384x640 1 person, 51.9ms\n",
      "image 266/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame353-SINGLE.jpeg: 384x640 1 person, 54.6ms\n",
      "image 267/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame354-SINGLE.jpeg: 384x640 2 persons, 50.6ms\n",
      "image 268/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame355-SINGLE.jpeg: 384x640 1 person, 58.4ms\n",
      "image 269/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame356-SINGLE.jpeg: 384x640 2 persons, 50.9ms\n",
      "image 270/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame357-SINGLE.jpeg: 384x640 2 persons, 49.3ms\n",
      "image 271/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame358-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 272/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame359-SINGLE.jpeg: 384x640 2 persons, 64.3ms\n",
      "image 273/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame36-SINGLE.jpeg: 384x640 2 persons, 52.1ms\n",
      "image 274/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame360-SINGLE.jpeg: 384x640 2 persons, 50.9ms\n",
      "image 275/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame361-SINGLE.jpeg: 384x640 2 persons, 50.7ms\n",
      "image 276/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame362-SINGLE.jpeg: 384x640 2 persons, 55.5ms\n",
      "image 277/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame363-SINGLE.jpeg: 384x640 2 persons, 55.5ms\n",
      "image 278/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame364-SINGLE.jpeg: 384x640 2 persons, 53.0ms\n",
      "image 279/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame365-SINGLE.jpeg: 384x640 2 persons, 56.6ms\n",
      "image 280/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame366-SINGLE.jpeg: 384x640 2 persons, 63.2ms\n",
      "image 281/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame367-SINGLE.jpeg: 384x640 2 persons, 53.9ms\n",
      "image 282/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame368-SINGLE.jpeg: 384x640 2 persons, 49.7ms\n",
      "image 283/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame369-SINGLE.jpeg: 384x640 2 persons, 51.6ms\n",
      "image 284/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame37-SINGLE.jpeg: 384x640 2 persons, 61.3ms\n",
      "image 285/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame370-SINGLE.jpeg: 384x640 2 persons, 53.5ms\n",
      "image 286/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame371-SINGLE.jpeg: 384x640 2 persons, 51.3ms\n",
      "image 287/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame372-SINGLE.jpeg: 384x640 2 persons, 51.9ms\n",
      "image 288/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame373-SINGLE.jpeg: 384x640 1 person, 79.5ms\n",
      "image 289/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame374-SINGLE.jpeg: 384x640 1 person, 57.5ms\n",
      "image 290/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame375-SINGLE.jpeg: 384x640 1 person, 56.7ms\n",
      "image 291/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame376-SINGLE.jpeg: 384x640 1 person, 58.2ms\n",
      "image 292/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame377-SINGLE.jpeg: 384x640 1 person, 51.7ms\n",
      "image 293/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame378-SINGLE.jpeg: 384x640 2 persons, 49.9ms\n",
      "image 294/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame379-SINGLE.jpeg: 384x640 1 person, 56.1ms\n",
      "image 295/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame38-SINGLE.jpeg: 384x640 2 persons, 61.6ms\n",
      "image 296/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame380-SINGLE.jpeg: 384x640 2 persons, 56.0ms\n",
      "image 297/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame381-SINGLE.jpeg: 384x640 2 persons, 56.3ms\n",
      "image 298/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame382-SINGLE.jpeg: 384x640 2 persons, 56.7ms\n",
      "image 299/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame383-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 300/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame384-SINGLE.jpeg: 384x640 2 persons, 58.1ms\n",
      "image 301/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame385-SINGLE.jpeg: 384x640 2 persons, 55.0ms\n",
      "image 302/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame386-SINGLE.jpeg: 384x640 2 persons, 51.7ms\n",
      "image 303/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame387-SINGLE.jpeg: 384x640 2 persons, 50.7ms\n",
      "image 304/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame388-SINGLE.jpeg: 384x640 2 persons, 54.4ms\n",
      "image 305/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame389-SINGLE.jpeg: 384x640 2 persons, 58.8ms\n",
      "image 306/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame39-SINGLE.jpeg: 384x640 2 persons, 56.8ms\n",
      "image 307/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame390-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 308/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame391-SINGLE.jpeg: 384x640 2 persons, 56.9ms\n",
      "image 309/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame392-SINGLE.jpeg: 384x640 2 persons, 56.2ms\n",
      "image 310/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame393-SINGLE.jpeg: 384x640 2 persons, 56.9ms\n",
      "image 311/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame394-SINGLE.jpeg: 384x640 2 persons, 56.1ms\n",
      "image 312/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame395-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 313/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame396-SINGLE.jpeg: 384x640 2 persons, 52.7ms\n",
      "image 314/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame397-SINGLE.jpeg: 384x640 2 persons, 57.2ms\n",
      "image 315/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame398-SINGLE.jpeg: 384x640 2 persons, 54.1ms\n",
      "image 316/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame399-SINGLE.jpeg: 384x640 2 persons, 65.2ms\n",
      "image 317/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame40-SINGLE.jpeg: 384x640 2 persons, 63.2ms\n",
      "image 318/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame400-SINGLE.jpeg: 384x640 2 persons, 54.9ms\n",
      "image 319/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame401-SINGLE.jpeg: 384x640 2 persons, 53.2ms\n",
      "image 320/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame402-SINGLE.jpeg: 384x640 2 persons, 56.8ms\n",
      "image 321/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame403-SINGLE.jpeg: 384x640 2 persons, 50.8ms\n",
      "image 322/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame404-SINGLE.jpeg: 384x640 2 persons, 52.7ms\n",
      "image 323/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame405-SINGLE.jpeg: 384x640 2 persons, 52.3ms\n",
      "image 324/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame406-SINGLE.jpeg: 384x640 2 persons, 51.6ms\n",
      "image 325/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame407-SINGLE.jpeg: 384x640 3 persons, 54.9ms\n",
      "image 326/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame408-SINGLE.jpeg: 384x640 3 persons, 57.6ms\n",
      "image 327/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame409-SINGLE.jpeg: 384x640 3 persons, 59.5ms\n",
      "image 328/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame41-SINGLE.jpeg: 384x640 2 persons, 56.2ms\n",
      "image 329/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame410-SINGLE.jpeg: 384x640 3 persons, 61.6ms\n",
      "image 330/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame411-SINGLE.jpeg: 384x640 3 persons, 56.1ms\n",
      "image 331/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame412-SINGLE.jpeg: 384x640 3 persons, 52.6ms\n",
      "image 332/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame413-SINGLE.jpeg: 384x640 2 persons, 55.0ms\n",
      "image 333/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame414-SINGLE.jpeg: 384x640 2 persons, 52.2ms\n",
      "image 334/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame415-SINGLE.jpeg: 384x640 2 persons, 50.3ms\n",
      "image 335/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame416-SINGLE.jpeg: 384x640 2 persons, 53.3ms\n",
      "image 336/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame417-SINGLE.jpeg: 384x640 2 persons, 61.6ms\n",
      "image 337/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame418-SINGLE.jpeg: 384x640 2 persons, 53.2ms\n",
      "image 338/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame419-SINGLE.jpeg: 384x640 2 persons, 53.2ms\n",
      "image 339/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame42-SINGLE.jpeg: 384x640 2 persons, 58.0ms\n",
      "image 340/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame420-SINGLE.jpeg: 384x640 2 persons, 55.1ms\n",
      "image 341/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame421-SINGLE.jpeg: 384x640 2 persons, 1 tennis racket, 52.2ms\n",
      "image 342/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame422-SINGLE.jpeg: 384x640 2 persons, 50.0ms\n",
      "image 343/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame423-SINGLE.jpeg: 384x640 2 persons, 51.9ms\n",
      "image 344/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame424-SINGLE.jpeg: 384x640 2 persons, 65.2ms\n",
      "image 345/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame425-SINGLE.jpeg: 384x640 2 persons, 101.0ms\n",
      "image 346/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame426-SINGLE.jpeg: 384x640 2 persons, 54.2ms\n",
      "image 347/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame427-SINGLE.jpeg: 384x640 2 persons, 51.6ms\n",
      "image 348/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame428-SINGLE.jpeg: 384x640 2 persons, 83.7ms\n",
      "image 349/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame429-SINGLE.jpeg: 384x640 2 persons, 52.6ms\n",
      "image 350/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame43-SINGLE.jpeg: 384x640 2 persons, 55.6ms\n",
      "image 351/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame430-SINGLE.jpeg: 384x640 2 persons, 57.7ms\n",
      "image 352/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame431-SINGLE.jpeg: 384x640 2 persons, 56.0ms\n",
      "image 353/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame432-SINGLE.jpeg: 384x640 2 persons, 49.1ms\n",
      "image 354/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame433-SINGLE.jpeg: 384x640 2 persons, 52.2ms\n",
      "image 355/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame434-SINGLE.jpeg: 384x640 3 persons, 60.4ms\n",
      "image 356/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame435-SINGLE.jpeg: 384x640 2 persons, 56.8ms\n",
      "image 357/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame436-SINGLE.jpeg: 384x640 2 persons, 51.6ms\n",
      "image 358/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame437-SINGLE.jpeg: 384x640 2 persons, 51.1ms\n",
      "image 359/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame438-SINGLE.jpeg: 384x640 2 persons, 62.4ms\n",
      "image 360/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame439-SINGLE.jpeg: 384x640 2 persons, 64.0ms\n",
      "image 361/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame44-SINGLE.jpeg: 384x640 2 persons, 53.8ms\n",
      "image 362/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame440-SINGLE.jpeg: 384x640 3 persons, 57.6ms\n",
      "image 363/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame441-SINGLE.jpeg: 384x640 3 persons, 56.8ms\n",
      "image 364/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame442-SINGLE.jpeg: 384x640 3 persons, 50.2ms\n",
      "image 365/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame443-SINGLE.jpeg: 384x640 3 persons, 52.3ms\n",
      "image 366/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame444-SINGLE.jpeg: 384x640 3 persons, 49.5ms\n",
      "image 367/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame445-SINGLE.jpeg: 384x640 2 persons, 53.1ms\n",
      "image 368/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame446-SINGLE.jpeg: 384x640 2 persons, 54.8ms\n",
      "image 369/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame447-SINGLE.jpeg: 384x640 2 persons, 77.2ms\n",
      "image 370/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame448-SINGLE.jpeg: 384x640 2 persons, 56.8ms\n",
      "image 371/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame449-SINGLE.jpeg: 384x640 2 persons, 52.9ms\n",
      "image 372/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame45-SINGLE.jpeg: 384x640 2 persons, 51.2ms\n",
      "image 373/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame450-SINGLE.jpeg: 384x640 2 persons, 49.7ms\n",
      "image 374/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame451-SINGLE.jpeg: 384x640 2 persons, 58.8ms\n",
      "image 375/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame452-SINGLE.jpeg: 384x640 2 persons, 56.5ms\n",
      "image 376/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame453-SINGLE.jpeg: 384x640 2 persons, 56.4ms\n",
      "image 377/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame454-SINGLE.jpeg: 384x640 2 persons, 59.6ms\n",
      "image 378/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame455-SINGLE.jpeg: 384x640 2 persons, 60.0ms\n",
      "image 379/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame456-SINGLE.jpeg: 384x640 2 persons, 60.8ms\n",
      "image 380/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame457-SINGLE.jpeg: 384x640 2 persons, 57.8ms\n",
      "image 381/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame458-SINGLE.jpeg: 384x640 2 persons, 59.6ms\n",
      "image 382/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame459-SINGLE.jpeg: 384x640 2 persons, 55.0ms\n",
      "image 383/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame46-SINGLE.jpeg: 384x640 2 persons, 54.9ms\n",
      "image 384/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame460-SINGLE.jpeg: 384x640 2 persons, 54.4ms\n",
      "image 385/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame461-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 386/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame462-SINGLE.jpeg: 384x640 2 persons, 1 sports ball, 52.6ms\n",
      "image 387/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame463-SINGLE.jpeg: 384x640 2 persons, 51.5ms\n",
      "image 388/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame464-SINGLE.jpeg: 384x640 2 persons, 52.4ms\n",
      "image 389/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame465-SINGLE.jpeg: 384x640 2 persons, 51.5ms\n",
      "image 390/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame466-SINGLE.jpeg: 384x640 2 persons, 51.9ms\n",
      "image 391/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame467-SINGLE.jpeg: 384x640 2 persons, 51.8ms\n",
      "image 392/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame468-SINGLE.jpeg: 384x640 2 persons, 59.4ms\n",
      "image 393/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame469-SINGLE.jpeg: 384x640 2 persons, 55.4ms\n",
      "image 394/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame47-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 395/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame470-SINGLE.jpeg: 384x640 2 persons, 51.2ms\n",
      "image 396/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame471-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 397/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame472-SINGLE.jpeg: 384x640 2 persons, 60.6ms\n",
      "image 398/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame473-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 399/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame474-SINGLE.jpeg: 384x640 2 persons, 58.1ms\n",
      "image 400/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame475-SINGLE.jpeg: 384x640 2 persons, 55.1ms\n",
      "image 401/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame476-SINGLE.jpeg: 384x640 2 persons, 49.6ms\n",
      "image 402/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame477-SINGLE.jpeg: 384x640 2 persons, 51.8ms\n",
      "image 403/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame478-SINGLE.jpeg: 384x640 2 persons, 59.6ms\n",
      "image 404/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame479-SINGLE.jpeg: 384x640 2 persons, 54.0ms\n",
      "image 405/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame48-SINGLE.jpeg: 384x640 2 persons, 57.1ms\n",
      "image 406/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame480-SINGLE.jpeg: 384x640 2 persons, 85.2ms\n",
      "image 407/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame481-SINGLE.jpeg: 384x640 2 persons, 57.0ms\n",
      "image 408/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame482-SINGLE.jpeg: 384x640 2 persons, 56.0ms\n",
      "image 409/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame483-SINGLE.jpeg: 384x640 2 persons, 51.5ms\n",
      "image 410/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame484-SINGLE.jpeg: 384x640 2 persons, 54.4ms\n",
      "image 411/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame485-SINGLE.jpeg: 384x640 2 persons, 61.7ms\n",
      "image 412/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame486-SINGLE.jpeg: 384x640 2 persons, 58.9ms\n",
      "image 413/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame487-SINGLE.jpeg: 384x640 3 persons, 48.9ms\n",
      "image 414/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame488-SINGLE.jpeg: 384x640 2 persons, 60.3ms\n",
      "image 415/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame489-SINGLE.jpeg: 384x640 2 persons, 57.1ms\n",
      "image 416/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame49-SINGLE.jpeg: 384x640 2 persons, 48.7ms\n",
      "image 417/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame490-SINGLE.jpeg: 384x640 2 persons, 52.2ms\n",
      "image 418/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame491-SINGLE.jpeg: 384x640 2 persons, 55.7ms\n",
      "image 419/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame492-SINGLE.jpeg: 384x640 2 persons, 55.5ms\n",
      "image 420/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame493-SINGLE.jpeg: 384x640 2 persons, 55.9ms\n",
      "image 421/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame494-SINGLE.jpeg: 384x640 2 persons, 60.0ms\n",
      "image 422/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame495-SINGLE.jpeg: 384x640 2 persons, 55.0ms\n",
      "image 423/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame496-SINGLE.jpeg: 384x640 2 persons, 48.0ms\n",
      "image 424/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame497-SINGLE.jpeg: 384x640 2 persons, 50.4ms\n",
      "image 425/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame498-SINGLE.jpeg: 384x640 2 persons, 63.2ms\n",
      "image 426/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame499-SINGLE.jpeg: 384x640 2 persons, 56.5ms\n",
      "image 427/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame50-SINGLE.jpeg: 384x640 2 persons, 60.2ms\n",
      "image 428/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame500-SINGLE.jpeg: 384x640 2 persons, 55.6ms\n",
      "image 429/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame501-SINGLE.jpeg: 384x640 2 persons, 54.6ms\n",
      "image 430/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame51-SINGLE.jpeg: 384x640 2 persons, 48.7ms\n",
      "image 431/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame52-SINGLE.jpeg: 384x640 2 persons, 57.2ms\n",
      "image 432/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame53-SINGLE.jpeg: 384x640 2 persons, 57.2ms\n",
      "image 433/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame54-SINGLE.jpeg: 384x640 2 persons, 49.6ms\n",
      "image 434/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame55-SINGLE.jpeg: 384x640 2 persons, 56.9ms\n",
      "image 435/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame56-SINGLE.jpeg: 384x640 2 persons, 62.3ms\n",
      "image 436/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame57-SINGLE.jpeg: 384x640 2 persons, 54.6ms\n",
      "image 437/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame58-SINGLE.jpeg: 384x640 2 persons, 60.4ms\n",
      "image 438/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame59-SINGLE.jpeg: 384x640 2 persons, 55.2ms\n",
      "image 439/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame60-SINGLE.jpeg: 384x640 2 persons, 50.7ms\n",
      "image 440/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame61-SINGLE.jpeg: 384x640 2 persons, 51.6ms\n",
      "image 441/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame62-SINGLE.jpeg: 384x640 2 persons, 58.3ms\n",
      "image 442/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame63-SINGLE.jpeg: 384x640 2 persons, 52.1ms\n",
      "image 443/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame64-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 444/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame65-SINGLE.jpeg: 384x640 2 persons, 56.0ms\n",
      "image 445/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame66-SINGLE.jpeg: 384x640 2 persons, 61.2ms\n",
      "image 446/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame67-SINGLE.jpeg: 384x640 2 persons, 50.1ms\n",
      "image 447/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame68-SINGLE.jpeg: 384x640 2 persons, 53.4ms\n",
      "image 448/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame69-SINGLE.jpeg: 384x640 2 persons, 72.7ms\n",
      "image 449/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame70-SINGLE.jpeg: 384x640 2 persons, 59.0ms\n",
      "image 450/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame71-SINGLE.jpeg: 384x640 2 persons, 54.8ms\n",
      "image 451/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame72-SINGLE.jpeg: 384x640 2 persons, 59.2ms\n",
      "image 452/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame73-SINGLE.jpeg: 384x640 2 persons, 66.3ms\n",
      "image 453/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame74-SINGLE.jpeg: 384x640 2 persons, 56.1ms\n",
      "image 454/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame75-SINGLE.jpeg: 384x640 2 persons, 55.8ms\n",
      "image 455/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame76-SINGLE.jpeg: 384x640 2 persons, 58.1ms\n",
      "image 456/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame77-SINGLE.jpeg: 384x640 2 persons, 52.1ms\n",
      "image 457/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame78-SINGLE.jpeg: 384x640 2 persons, 53.9ms\n",
      "image 458/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame79-SINGLE.jpeg: 384x640 2 persons, 50.0ms\n",
      "image 459/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame80-SINGLE.jpeg: 384x640 2 persons, 53.4ms\n",
      "image 460/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame81-SINGLE.jpeg: 384x640 2 persons, 62.0ms\n",
      "image 461/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame82-SINGLE.jpeg: 384x640 2 persons, 85.6ms\n",
      "image 462/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame83-SINGLE.jpeg: 384x640 2 persons, 58.8ms\n",
      "image 463/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame84-SINGLE.jpeg: 384x640 2 persons, 58.9ms\n",
      "image 464/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame85-SINGLE.jpeg: 384x640 2 persons, 60.8ms\n",
      "image 465/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame86-SINGLE.jpeg: 384x640 2 persons, 60.7ms\n",
      "image 466/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame87-SINGLE.jpeg: 384x640 2 persons, 58.9ms\n",
      "image 467/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame88-SINGLE.jpeg: 384x640 2 persons, 58.4ms\n",
      "image 468/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame89-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 469/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame90-SINGLE.jpeg: 384x640 2 persons, 55.3ms\n",
      "image 470/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame91-SINGLE.jpeg: 384x640 2 persons, 54.0ms\n",
      "image 471/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame92-SINGLE.jpeg: 384x640 2 persons, 54.0ms\n",
      "image 472/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame93-SINGLE.jpeg: 384x640 2 persons, 52.3ms\n",
      "image 473/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame94-SINGLE.jpeg: 384x640 2 persons, 54.6ms\n",
      "image 474/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame95-SINGLE.jpeg: 384x640 2 persons, 55.6ms\n",
      "image 475/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame96-SINGLE.jpeg: 384x640 2 persons, 70.4ms\n",
      "image 476/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame97-SINGLE.jpeg: 384x640 2 persons, 58.5ms\n",
      "image 477/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame98-SINGLE.jpeg: 384x640 2 persons, 50.2ms\n",
      "image 478/478 /Users/zhangzijun/ComputerVision/yolov5-master/data/images/frame99-SINGLE.jpeg: 384x640 2 persons, 53.6ms\n",
      "Speed: 0.4ms pre-process, 57.5ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5-master/runs/detect/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Task 3\n",
    "'''\n",
    "I used YOLOv5 to detect the athletes by adjusting some parameters such as confidence level. The source images are in the folder named \"yolov5-master/data/images\". And the results would be output\n",
    "to the folder named \"yolov5-master/runs/detect/exp\".\n",
    "'''\n",
    "%run yolov5-master/detect.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 46.6ms\n",
      "Speed: 1.6ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 person, 42.2ms\n",
      "Speed: 1.3ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.4ms\n",
      "Speed: 1.3ms preprocess, 49.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.4ms\n",
      "Speed: 1.5ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.9ms\n",
      "Speed: 1.8ms preprocess, 51.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Speed: 1.3ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.8ms\n",
      "Speed: 1.1ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.7ms\n",
      "Speed: 1.2ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Speed: 1.0ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 1.1ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.7ms\n",
      "Speed: 1.1ms preprocess, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.1ms\n",
      "Speed: 1.6ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.2ms\n",
      "Speed: 1.2ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.7ms\n",
      "Speed: 1.2ms preprocess, 36.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.8ms\n",
      "Speed: 1.1ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.7ms\n",
      "Speed: 0.9ms preprocess, 35.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.8ms\n",
      "Speed: 1.2ms preprocess, 84.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Speed: 0.9ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Speed: 0.9ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.2ms\n",
      "Speed: 0.9ms preprocess, 43.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.4ms\n",
      "Speed: 1.1ms preprocess, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 55.1ms\n",
      "Speed: 1.2ms preprocess, 55.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.9ms\n",
      "Speed: 0.9ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.9ms\n",
      "Speed: 1.1ms preprocess, 47.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 0.9ms preprocess, 42.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 0.9ms preprocess, 43.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.2ms\n",
      "Speed: 1.4ms preprocess, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.9ms\n",
      "Speed: 0.9ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 1.2ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.6ms\n",
      "Speed: 1.3ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.3ms\n",
      "Speed: 1.1ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.4ms\n",
      "Speed: 3.5ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.9ms\n",
      "Speed: 1.0ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.3ms\n",
      "Speed: 1.1ms preprocess, 42.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 0.9ms preprocess, 43.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.9ms\n",
      "Speed: 2.3ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.2ms\n",
      "Speed: 1.3ms preprocess, 48.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.3ms\n",
      "Speed: 0.9ms preprocess, 50.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.3ms\n",
      "Speed: 1.3ms preprocess, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.4ms\n",
      "Speed: 1.0ms preprocess, 58.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.8ms\n",
      "Speed: 0.9ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.7ms\n",
      "Speed: 0.9ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.3ms\n",
      "Speed: 1.0ms preprocess, 32.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.3ms\n",
      "Speed: 1.1ms preprocess, 37.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Speed: 0.9ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.3ms\n",
      "Speed: 1.3ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.0ms\n",
      "Speed: 1.1ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.2ms\n",
      "Speed: 1.2ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.0ms\n",
      "Speed: 1.1ms preprocess, 50.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.4ms\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.0ms\n",
      "Speed: 0.9ms preprocess, 42.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.0ms\n",
      "Speed: 1.1ms preprocess, 50.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.7ms\n",
      "Speed: 1.0ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.9ms\n",
      "Speed: 1.1ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.3ms preprocess, 35.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.0ms\n",
      "Speed: 0.9ms preprocess, 36.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.0ms preprocess, 36.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Speed: 1.3ms preprocess, 35.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Speed: 1.1ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.3ms\n",
      "Speed: 0.9ms preprocess, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.3ms\n",
      "Speed: 0.9ms preprocess, 40.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.6ms\n",
      "Speed: 1.1ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Speed: 0.9ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 51.5ms\n",
      "Speed: 1.3ms preprocess, 51.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.1ms\n",
      "Speed: 0.9ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.9ms\n",
      "Speed: 1.2ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 1.1ms preprocess, 40.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.2ms\n",
      "Speed: 0.9ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 0.9ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.2ms\n",
      "Speed: 1.2ms preprocess, 37.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 1.1ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.0ms\n",
      "Speed: 1.1ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.9ms\n",
      "Speed: 7.1ms preprocess, 46.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Speed: 3.0ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.8ms\n",
      "Speed: 1.3ms preprocess, 42.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.9ms\n",
      "Speed: 0.9ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 49.8ms\n",
      "Speed: 0.9ms preprocess, 49.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.6ms\n",
      "Speed: 1.2ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 55.9ms\n",
      "Speed: 1.6ms preprocess, 55.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.4ms\n",
      "Speed: 1.1ms preprocess, 45.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.3ms\n",
      "Speed: 0.9ms preprocess, 42.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.2ms\n",
      "Speed: 0.9ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.3ms\n",
      "Speed: 1.0ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 48.1ms\n",
      "Speed: 1.1ms preprocess, 48.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 55.3ms\n",
      "Speed: 1.2ms preprocess, 55.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.3ms\n",
      "Speed: 0.9ms preprocess, 43.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.8ms\n",
      "Speed: 11.6ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.6ms\n",
      "Speed: 1.1ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.9ms\n",
      "Speed: 1.1ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.7ms\n",
      "Speed: 0.9ms preprocess, 40.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.4ms\n",
      "Speed: 1.2ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.0ms\n",
      "Speed: 0.9ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.7ms\n",
      "Speed: 1.2ms preprocess, 43.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.4ms\n",
      "Speed: 1.1ms preprocess, 52.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.2ms\n",
      "Speed: 1.0ms preprocess, 55.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.3ms\n",
      "Speed: 0.9ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.3ms\n",
      "Speed: 1.2ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.7ms\n",
      "Speed: 1.1ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.0ms\n",
      "Speed: 0.9ms preprocess, 45.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 1.4ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.3ms\n",
      "Speed: 1.1ms preprocess, 53.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 72.5ms\n",
      "Speed: 1.4ms preprocess, 72.5ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.1ms\n",
      "Speed: 1.2ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.1ms\n",
      "Speed: 0.9ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.2ms\n",
      "Speed: 1.3ms preprocess, 46.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.4ms\n",
      "Speed: 1.0ms preprocess, 57.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.0ms\n",
      "Speed: 1.2ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.2ms\n",
      "Speed: 1.4ms preprocess, 43.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Speed: 1.4ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Speed: 0.9ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.3ms\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 52.8ms\n",
      "Speed: 0.9ms preprocess, 52.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.5ms\n",
      "Speed: 1.3ms preprocess, 43.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.7ms\n",
      "Speed: 1.2ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.4ms\n",
      "Speed: 0.9ms preprocess, 49.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 48.6ms\n",
      "Speed: 1.2ms preprocess, 48.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.1ms\n",
      "Speed: 1.6ms preprocess, 44.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.9ms\n",
      "Speed: 1.3ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.4ms\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Speed: 1.4ms preprocess, 36.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Speed: 1.1ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.3ms\n",
      "Speed: 1.1ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.0ms\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Speed: 0.9ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.4ms\n",
      "Speed: 0.9ms preprocess, 36.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.6ms\n",
      "Speed: 0.9ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 52.4ms\n",
      "Speed: 1.0ms preprocess, 52.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 49.5ms\n",
      "Speed: 1.3ms preprocess, 49.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.3ms\n",
      "Speed: 1.4ms preprocess, 49.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.7ms\n",
      "Speed: 1.2ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.2ms\n",
      "Speed: 0.9ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.7ms\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.3ms\n",
      "Speed: 1.1ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.1ms\n",
      "Speed: 1.1ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.1ms\n",
      "Speed: 1.2ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.2ms\n",
      "Speed: 1.2ms preprocess, 47.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.1ms\n",
      "Speed: 0.9ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.6ms\n",
      "Speed: 1.2ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.3ms\n",
      "Speed: 1.3ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.3ms\n",
      "Speed: 1.1ms preprocess, 43.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.2ms\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.2ms\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.4ms\n",
      "Speed: 1.2ms preprocess, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.9ms\n",
      "Speed: 1.0ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.6ms\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.4ms\n",
      "Speed: 1.5ms preprocess, 41.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.1ms\n",
      "Speed: 1.1ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.3ms\n",
      "Speed: 1.4ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.3ms\n",
      "Speed: 1.4ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.4ms\n",
      "Speed: 1.2ms preprocess, 40.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 51.5ms\n",
      "Speed: 1.4ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.4ms\n",
      "Speed: 1.2ms preprocess, 46.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Speed: 1.2ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 65.5ms\n",
      "Speed: 1.1ms preprocess, 65.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.3ms\n",
      "Speed: 1.0ms preprocess, 37.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.7ms\n",
      "Speed: 0.9ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.8ms\n",
      "Speed: 0.9ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.9ms\n",
      "Speed: 1.1ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.9ms\n",
      "Speed: 0.9ms preprocess, 33.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.7ms\n",
      "Speed: 1.2ms preprocess, 35.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.3ms\n",
      "Speed: 1.0ms preprocess, 36.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.6ms\n",
      "Speed: 3.6ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.1ms\n",
      "Speed: 0.9ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Speed: 1.1ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Speed: 0.9ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.5ms\n",
      "Speed: 2.5ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Speed: 0.9ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Speed: 1.0ms preprocess, 35.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.9ms\n",
      "Speed: 1.0ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Speed: 1.3ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 0.9ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.6ms\n",
      "Speed: 1.3ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.1ms\n",
      "Speed: 0.9ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.7ms\n",
      "Speed: 1.1ms preprocess, 37.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Speed: 1.0ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Speed: 0.9ms preprocess, 35.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.6ms\n",
      "Speed: 1.1ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.8ms\n",
      "Speed: 1.0ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.4ms\n",
      "Speed: 1.0ms preprocess, 35.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Speed: 1.1ms preprocess, 36.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Speed: 0.9ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.1ms\n",
      "Speed: 0.9ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.7ms\n",
      "Speed: 0.9ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.8ms\n",
      "Speed: 1.3ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.2ms\n",
      "Speed: 1.3ms preprocess, 36.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.4ms\n",
      "Speed: 1.4ms preprocess, 39.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.8ms\n",
      "Speed: 0.9ms preprocess, 38.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Speed: 0.9ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Speed: 0.9ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.6ms\n",
      "Speed: 1.3ms preprocess, 41.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.1ms\n",
      "Speed: 1.3ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.8ms\n",
      "Speed: 0.9ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.4ms\n",
      "Speed: 1.0ms preprocess, 33.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.1ms\n",
      "Speed: 1.2ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.6ms\n",
      "Speed: 0.9ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.4ms\n",
      "Speed: 1.3ms preprocess, 36.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.5ms\n",
      "Speed: 14.8ms preprocess, 53.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.3ms\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.3ms\n",
      "Speed: 1.1ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.4ms\n",
      "Speed: 1.2ms preprocess, 42.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Speed: 1.1ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.2ms\n",
      "Speed: 1.1ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.1ms\n",
      "Speed: 1.3ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.9ms\n",
      "Speed: 1.0ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.9ms\n",
      "Speed: 1.4ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.7ms\n",
      "Speed: 1.3ms preprocess, 45.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.1ms\n",
      "Speed: 1.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.2ms\n",
      "Speed: 1.1ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.1ms\n",
      "Speed: 1.6ms preprocess, 41.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.7ms\n",
      "Speed: 1.2ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.4ms\n",
      "Speed: 1.5ms preprocess, 42.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.8ms\n",
      "Speed: 1.1ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.1ms\n",
      "Speed: 1.1ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Speed: 0.9ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.3ms\n",
      "Speed: 0.9ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.8ms\n",
      "Speed: 1.1ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.4ms\n",
      "Speed: 1.2ms preprocess, 31.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Speed: 1.1ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.1ms\n",
      "Speed: 1.1ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.3ms\n",
      "Speed: 0.9ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.9ms\n",
      "Speed: 0.9ms preprocess, 36.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.7ms\n",
      "Speed: 1.1ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Speed: 0.9ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.7ms\n",
      "Speed: 0.9ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Speed: 0.9ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.1ms\n",
      "Speed: 1.3ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.6ms\n",
      "Speed: 1.1ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.8ms\n",
      "Speed: 1.2ms preprocess, 33.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Speed: 1.3ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.4ms\n",
      "Speed: 1.2ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.1ms\n",
      "Speed: 0.9ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.0ms\n",
      "Speed: 1.2ms preprocess, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.9ms\n",
      "Speed: 1.1ms preprocess, 33.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 0.9ms preprocess, 36.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Speed: 0.9ms preprocess, 35.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.1ms preprocess, 36.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Speed: 1.1ms preprocess, 37.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.8ms\n",
      "Speed: 0.9ms preprocess, 33.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Speed: 0.9ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.9ms\n",
      "Speed: 1.1ms preprocess, 32.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Speed: 1.0ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.4ms\n",
      "Speed: 1.0ms preprocess, 59.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.9ms\n",
      "Speed: 1.3ms preprocess, 82.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "Speed: 1.2ms preprocess, 46.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.2ms\n",
      "Speed: 1.2ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.8ms\n",
      "Speed: 1.1ms preprocess, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.9ms\n",
      "Speed: 1.1ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.1ms\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 1.6ms preprocess, 44.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.4ms\n",
      "Speed: 1.6ms preprocess, 39.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.4ms\n",
      "Speed: 0.9ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.7ms\n",
      "Speed: 1.2ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.3ms\n",
      "Speed: 1.1ms preprocess, 46.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.4ms\n",
      "Speed: 1.2ms preprocess, 50.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.3ms preprocess, 48.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.4ms\n",
      "Speed: 1.1ms preprocess, 50.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 0.9ms preprocess, 48.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.0ms\n",
      "Speed: 1.1ms preprocess, 46.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.4ms\n",
      "Speed: 1.2ms preprocess, 43.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.1ms\n",
      "Speed: 0.9ms preprocess, 42.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 51.2ms\n",
      "Speed: 1.2ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 56.6ms\n",
      "Speed: 1.3ms preprocess, 56.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.3ms preprocess, 46.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 53.8ms\n",
      "Speed: 1.0ms preprocess, 53.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.7ms\n",
      "Speed: 4.1ms preprocess, 40.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.3ms\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.3ms preprocess, 37.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 1.4ms preprocess, 46.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 1.2ms preprocess, 44.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.3ms\n",
      "Speed: 1.2ms preprocess, 46.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 1.3ms preprocess, 44.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.1ms preprocess, 36.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.9ms\n",
      "Speed: 1.1ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.7ms\n",
      "Speed: 1.7ms preprocess, 54.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.9ms\n",
      "Speed: 1.1ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.4ms\n",
      "Speed: 1.3ms preprocess, 42.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Speed: 1.1ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.9ms\n",
      "Speed: 1.4ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.8ms\n",
      "Speed: 0.9ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.4ms\n",
      "Speed: 1.3ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Speed: 1.1ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.9ms\n",
      "Speed: 1.3ms preprocess, 44.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.9ms\n",
      "Speed: 1.1ms preprocess, 42.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.4ms\n",
      "Speed: 1.2ms preprocess, 46.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.4ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.9ms\n",
      "Speed: 1.0ms preprocess, 44.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 48.3ms\n",
      "Speed: 0.9ms preprocess, 48.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.6ms\n",
      "Speed: 0.9ms preprocess, 50.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Speed: 1.4ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.3ms\n",
      "Speed: 1.4ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.8ms\n",
      "Speed: 1.8ms preprocess, 43.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Speed: 0.9ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.3ms\n",
      "Speed: 0.9ms preprocess, 53.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.3ms\n",
      "Speed: 2.1ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.6ms\n",
      "Speed: 1.1ms preprocess, 37.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.8ms\n",
      "Speed: 1.2ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.3ms\n",
      "Speed: 1.1ms preprocess, 36.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.8ms\n",
      "Speed: 1.4ms preprocess, 43.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.9ms\n",
      "Speed: 1.1ms preprocess, 52.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 50.6ms\n",
      "Speed: 2.2ms preprocess, 50.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.3ms\n",
      "Speed: 1.2ms preprocess, 52.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.3ms\n",
      "Speed: 2.8ms preprocess, 51.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.8ms\n",
      "Speed: 1.2ms preprocess, 76.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.8ms\n",
      "Speed: 1.1ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Speed: 1.2ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.5ms\n",
      "Speed: 1.1ms preprocess, 55.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.2ms\n",
      "Speed: 1.1ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.2ms\n",
      "Speed: 1.3ms preprocess, 43.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Speed: 0.9ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 0.9ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.8ms\n",
      "Speed: 1.0ms preprocess, 38.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.8ms\n",
      "Speed: 1.2ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.0ms\n",
      "Speed: 1.1ms preprocess, 36.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 1.1ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.1ms\n",
      "Speed: 1.3ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.4ms\n",
      "Speed: 1.1ms preprocess, 46.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.9ms\n",
      "Speed: 1.2ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 1.8ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 1.1ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.3ms\n",
      "Speed: 1.2ms preprocess, 37.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.4ms\n",
      "Speed: 1.0ms preprocess, 35.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.8ms\n",
      "Speed: 1.1ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.3ms\n",
      "Speed: 1.0ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Speed: 0.9ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.7ms\n",
      "Speed: 1.1ms preprocess, 36.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 48.8ms\n",
      "Speed: 1.5ms preprocess, 48.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.2ms\n",
      "Speed: 1.2ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.1ms\n",
      "Speed: 0.9ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.6ms\n",
      "Speed: 1.6ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.0ms\n",
      "Speed: 1.2ms preprocess, 42.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.8ms\n",
      "Speed: 1.0ms preprocess, 43.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Speed: 0.9ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 1.2ms preprocess, 37.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.3ms\n",
      "Speed: 1.1ms preprocess, 37.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.1ms\n",
      "Speed: 0.9ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Speed: 0.9ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.4ms\n",
      "Speed: 1.3ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.1ms\n",
      "Speed: 1.1ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.3ms\n",
      "Speed: 0.9ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.7ms\n",
      "Speed: 1.2ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.7ms\n",
      "Speed: 0.9ms preprocess, 60.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Speed: 0.9ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.6ms\n",
      "Speed: 1.2ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Speed: 1.3ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.6ms\n",
      "Speed: 0.9ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 0.9ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.8ms\n",
      "Speed: 1.3ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.3ms\n",
      "Speed: 0.9ms preprocess, 43.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.3ms\n",
      "Speed: 1.1ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.4ms\n",
      "Speed: 0.9ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.3ms\n",
      "Speed: 0.9ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.8ms\n",
      "Speed: 0.9ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Speed: 1.2ms preprocess, 36.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.9ms\n",
      "Speed: 1.0ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Speed: 0.8ms preprocess, 33.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.0ms\n",
      "Speed: 0.9ms preprocess, 35.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.7ms\n",
      "Speed: 0.9ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.4ms\n",
      "Speed: 1.2ms preprocess, 35.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.3ms preprocess, 37.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.2ms preprocess, 37.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.0ms\n",
      "Speed: 0.9ms preprocess, 36.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.1ms\n",
      "Speed: 0.9ms preprocess, 36.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Speed: 1.1ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 0.9ms preprocess, 34.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.8ms\n",
      "Speed: 0.9ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.8ms\n",
      "Speed: 1.2ms preprocess, 33.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.1ms\n",
      "Speed: 1.1ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Speed: 0.9ms preprocess, 36.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.6ms\n",
      "Speed: 0.9ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.5ms\n",
      "Speed: 1.4ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "#Task 4\n",
    "'''\n",
    "First, I merged the images filtered from Task 1 into a video. Then, I used YOLOv8 to track and detect the athletes in the video. The result\n",
    "video would be output to the folder named \"processed_source\".\n",
    "'''\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"processed_source/single\"\n",
    "cap = cv2.VideoCapture(video_path + \".avi\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter(video_path + \"_processed.mp4\", fourcc, 20.0, (frame_width, frame_height))\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        results = model.track(frame, conf = 0.6, classes = [0], persist=True)\n",
    "\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
